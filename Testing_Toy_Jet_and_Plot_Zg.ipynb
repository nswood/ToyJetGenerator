{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datagenerator import jet_data_generator \n",
    "# from plotutils import plot_event \n",
    "import matplotlib \n",
    "import time\n",
    "import os\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import h5py as h5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def load_binary_resonance_dataset(path, n_samples=-1):\n",
    "    with h5.File(path, 'r') as f:\n",
    "        data = f['data'][:n_samples]\n",
    "        labels = f['labels'][:n_samples].astype(str)\n",
    "        four_vectors = f['four_vectors'][:n_samples]\n",
    "    resonance_labels = labels[:,:,-1]\n",
    "    padding_mask = labels != '0'\n",
    "    binary_resonance_label = (labels != 'None') & (labels != '0')\n",
    "    return data, binary_resonance_label,four_vectors, padding_mask\n",
    "\n",
    "def train_test_val_split(data, binary_resonance_label, four_vectors, padding_mask, train_percent, val_percent, batch_size):\n",
    "    n_samples = data.shape[0]\n",
    "    n_train = int(n_samples * train_percent)\n",
    "    n_val = int(n_samples * val_percent)\n",
    "    n_test = n_samples - n_train - n_val\n",
    "\n",
    "    train_data = torch.tensor(data[:n_train])\n",
    "    val_data = torch.tensor(data[n_train:n_train + n_val])\n",
    "    test_data = torch.tensor(data[n_train + n_val:])\n",
    "\n",
    "    train_labels = torch.tensor(binary_resonance_label[:n_train])\n",
    "    val_labels = torch.tensor(binary_resonance_label[n_train:n_train + n_val])\n",
    "    test_labels = torch.tensor(binary_resonance_label[n_train + n_val:])\n",
    "\n",
    "    train_four_vectors = torch.tensor(four_vectors[:n_train])\n",
    "    val_four_vectors  = torch.tensor(four_vectors[n_train:n_train + n_val])\n",
    "    test_four_vectors  = torch.tensor(four_vectors[n_train + n_val:])\n",
    "\n",
    "    train_padding = torch.tensor(padding_mask[:n_train])\n",
    "    val_padding = torch.tensor(padding_mask[n_train:n_train + n_val])\n",
    "    test_padding = torch.tensor(padding_mask[n_train + n_val:])\n",
    "\n",
    "    train_dataset = TensorDataset(train_data, train_four_vectors, train_labels, train_padding)\n",
    "    val_dataset = TensorDataset(val_data, val_four_vectors,  val_labels, val_padding)\n",
    "    test_dataset = TensorDataset(test_data, test_four_vectors, test_labels, test_padding)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def prep_dataloaders(path,n_samples = -1,train_percent=0.8, val_percent=0.1, batch_size=32):\n",
    "    data, four_vectors, binary_resonance_label, padding_mask = load_binary_resonance_dataset(path, n_samples)\n",
    "    train_loader, val_loader, test_loader = train_test_val_split(data, binary_resonance_label, four_vectors, padding_mask, train_percent, val_percent, batch_size)\n",
    "    return train_loader, val_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize mock data for testing\n",
    "x_parts = torch.randn(100, 32, 3, 5)  # Shape [100, 32, 3, 5]\n",
    "selected_part_experts = torch.randn(100, 32, 3)  # Shape [100, 32, 3]\n",
    "shared_output = torch.randn(64)  # Shape [64]\n",
    "\n",
    "# Initialize proc_parts as a list of lists of lists of tensors\n",
    "proc_parts = [\n",
    "    [\n",
    "        [torch.randn(64), torch.randn(32),torch.randn(32)]  # 3 elements, each of shape [32]\n",
    "        for _ in range(32)  # 32 elements\n",
    "    ]\n",
    "    for _ in range(100)  # 100 elements\n",
    "]\n",
    "\n",
    "# part_router_output as a 3D tensor with scalar elements\n",
    "part_router_output = torch.randn(100, 32, 3)  # Shape [100, 32, 3]\n",
    "\n",
    "# Weights and other variables\n",
    "weights = torch.randn(2, 1)  # Shape [2, 1]\n",
    "cur = torch.randn(2, 32)  # Shape [2, 32]\n",
    "weighted_mean = torch.randn(96)  # Shape [96]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_parts.shape: torch.Size([100, 32, 3, 5])\n",
      "selected_part_experts.shape: torch.Size([100, 32, 3])\n",
      "len(proc_parts): 100\n",
      "len(proc_parts[0]): 32\n",
      "len(proc_parts[0][0]): 3\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "0\n",
      "shared_output.shape: torch.Size([64])\n",
      "1\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "2\n",
      "proc_parts[p][i][k].shape torch.Size([32])\n",
      "part_router_output[p, i, k].shape: torch.Size([])\n",
      "weights.shape: torch.Size([2, 1])\n",
      "cur.shape: torch.Size([2, 32])\n",
      "weighted_mean.shape: torch.Size([32])\n",
      "weighted_mean.shape: torch.Size([96])\n",
      "tan_cls_tokens_parts.shape: torch.Size([4, 100, 96])\n"
     ]
    }
   ],
   "source": [
    "shared_expert = True\n",
    "P, N, K, F = x_parts.shape\n",
    "print('x_parts.shape:',x_parts.shape)\n",
    "print('selected_part_experts.shape:',selected_part_experts.shape)\n",
    "\n",
    "print('len(proc_parts):',len(proc_parts))\n",
    "print('len(proc_parts[0]):',len(proc_parts[0]))\n",
    "print('len(proc_parts[0][0]):',len(proc_parts[0][0]))\n",
    "# proc_parts P x N x K x F\n",
    "# Weighted mean aggregation in tangent space\n",
    "tan_cls_tokens_parts = []\n",
    "for p in range(P):  # Particles\n",
    "    expert_combined = []\n",
    "    shared_output = None\n",
    "    for i in range(4):  # Batch\n",
    "        \n",
    "        cur = []\n",
    "        weights = []\n",
    "        for k in range(K):  # Experts\n",
    "            selected_k = k  # Extract integer index\n",
    "            \n",
    "            print(k)\n",
    "            if k == 0:  # Handle shared expert\n",
    "                shared_output = proc_parts[p][i][k]  # First output is shared expert\n",
    "                print('shared_output.shape:',shared_output.shape)\n",
    "            else:\n",
    "                cur.append(proc_parts[p][i][k])\n",
    "                print('proc_parts[p][i][k].shape',proc_parts[p][i][k].shape)\n",
    "            if not k==0:\n",
    "                weights.append(part_router_output[p, i, k])  # Select appropriate expert weight\n",
    "                print('part_router_output[p, i, k].shape:',part_router_output[p, i, k].shape)\n",
    "\n",
    "        weights = torch.softmax(torch.tensor(weights), dim=-1).unsqueeze(-1)\n",
    "        print('weights.shape:',weights.shape)\n",
    "        cur = torch.stack(cur, dim=0)  # Stack expert outputs per particle\n",
    "        \n",
    "        print('cur.shape:',cur.shape)\n",
    "        weighted_mean = torch.sum(cur * weights, dim=0)  # Aggregate across experts only\n",
    "        print('weighted_mean.shape:',weighted_mean.shape)\n",
    "\n",
    "        if shared_expert and shared_output is not None:\n",
    "            weighted_mean = torch.cat((shared_output, weighted_mean), dim=-1)\n",
    "        print('weighted_mean.shape:',weighted_mean.shape)\n",
    "        expert_combined.append(weighted_mean)\n",
    "    \n",
    "    tan_cls_tokens_parts.append(torch.stack(expert_combined, dim=0))\n",
    "\n",
    "tan_cls_tokens_parts = torch.stack(tan_cls_tokens_parts, dim=0).permute(1,0,2)  # N x P x F\n",
    "print('tan_cls_tokens_parts.shape:',tan_cls_tokens_parts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tan_cls_tokens_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 96])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tan_cls_tokens_parts[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = prep_dataloaders('processed_toy_resonaces_dataset_1_21_25/full_shower_dataset.h5', n_samples=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Particle Manifolds:\n",
      "====================\n",
      "====================\n",
      "Euclidean Manifold 0\n",
      "Stereographic Manifold: 1 Curvature: Parameter containing:\n",
      "tensor(-3., requires_grad=True)\n",
      "Stereographic Manifold: 2 Curvature: Parameter containing:\n",
      "tensor(-1.8000, requires_grad=True)\n",
      "Stereographic Manifold: 3 Curvature: Parameter containing:\n",
      "tensor(-0.6000, requires_grad=True)\n",
      "Stereographic Manifold: 4 Curvature: Parameter containing:\n",
      "tensor(0.6000, requires_grad=True)\n",
      "Stereographic Manifold: 5 Curvature: Parameter containing:\n",
      "tensor(1.8000, requires_grad=True)\n",
      "Stereographic Manifold: 6 Curvature: Parameter containing:\n",
      "tensor(3., requires_grad=True)\n",
      "====================\n",
      "==================== \n",
      "\n",
      "\n",
      "Jet Manifolds:\n",
      "====================\n",
      "====================\n",
      "Euclidean Manifold 0\n",
      "Stereographic Manifold: 1 Curvature: Parameter containing:\n",
      "tensor(-3., requires_grad=True)\n",
      "Stereographic Manifold: 2 Curvature: Parameter containing:\n",
      "tensor(-1.8000, requires_grad=True)\n",
      "Stereographic Manifold: 3 Curvature: Parameter containing:\n",
      "tensor(-0.6000, requires_grad=True)\n",
      "Stereographic Manifold: 4 Curvature: Parameter containing:\n",
      "tensor(0.6000, requires_grad=True)\n",
      "Stereographic Manifold: 5 Curvature: Parameter containing:\n",
      "tensor(1.8000, requires_grad=True)\n",
      "Stereographic Manifold: 6 Curvature: Parameter containing:\n",
      "tensor(3., requires_grad=True)\n",
      "====================\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.expanduser('~/weaver-core'))\n",
    "from weaver.nn.model.MoG_part_lvl_MLP import MoG_part_lvl_MLP\n",
    "\n",
    "model = MoG_part_lvl_MLP(input_dim =5, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = train_loader.dataset.tensors[0][0:10].permute(0,2,1).real\n",
    "test_four_vecs= train_loader.dataset.tensors[2][0:10].permute(0,2,1).real\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home11/nswood/weaver-core/weaver/nn/model/MoG_part_lvl_MLP.py:301: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur_x.shape: torch.Size([100, 5])\n",
      "cur_x.shape: torch.Size([100, 5])\n",
      "cur_x.shape: torch.Size([100, 5])\n",
      "cur_x.shape: torch.Size([100, 5])\n",
      "cur_x.shape: torch.Size([100, 5])\n",
      "cur_x.shape: torch.Size([100, 5])\n",
      "cur_x.shape: torch.Size([100, 5])\n",
      "cur_x.shape: torch.Size([100, 5])\n",
      "cur_x.shape: torch.Size([100, 5])\n",
      "cur_x.shape: torch.Size([100, 5])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_four_vecs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/n/holystore01/LABS/iaifi_lab/Users/nswood/mambaforge/envs/top_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1716\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1716\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/n/holystore01/LABS/iaifi_lab/Users/nswood/mambaforge/envs/top_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1723\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1724\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1725\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1726\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1727\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1730\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/weaver-core/weaver/nn/model/MoG_part_lvl_MLP.py:430\u001b[0m, in \u001b[0;36mMoG_part_lvl_MLP.forward\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    428\u001b[0m     shared_output \u001b[38;5;241m=\u001b[39m proc_parts[p][i][k]  \u001b[38;5;66;03m# First output is shared expert\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 430\u001b[0m     \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpart_manifolds[selected_k]\u001b[38;5;241m.\u001b[39mlogmap0(proc_parts[p][i][k]))\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshared_expert \u001b[38;5;129;01mand\u001b[39;00m k \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    432\u001b[0m     weights\u001b[38;5;241m.\u001b[39mappend(part_router_output[p, i, k])  \u001b[38;5;66;03m# Select appropriate expert weight\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "output = model(test_data, test_four_vecs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datagenerator_resonances_realistic import jet_data_generator as realistic_generator\n",
    "realistic_sig_2p_16part = realistic_generator(\n",
    "    massprior=\"signal\", \n",
    "    nprong=2, \n",
    "    nparticle=32, \n",
    "    doFixP=True, \n",
    "    resonance_data=[\n",
    "        {'mass': 180.0, 'relative_ratio': 1.0, 'decay_products': 3},\n",
    "        {'mass': 30.0, 'relative_ratio': 1.0, 'decay_products': 3},\n",
    "        {'mass': 80.0, 'relative_ratio': 1.0, 'decay_products': 2},\n",
    "        {'mass': 10.0, 'relative_ratio': 1.0, 'decay_products': 2},\n",
    "    ], \n",
    "    total_resonance_prob=0.15, # Adjust total resonance probability as desired\n",
    "    max_resonance_per_jet = 1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "realisticdata_sig_2p_16part = realistic_sig_2p_16part.generate_dataset(50,verbose = False)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget  # enable interactive widget backend\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "# Example prong-label color map\n",
    "color_map = {\n",
    "    -1: 'lightgray',\n",
    "     0: 'lightyellow',\n",
    "     1: 'lightcoral',\n",
    "     2: 'lightblue',\n",
    "     3: 'lightgreen',\n",
    "     4: 'plum'\n",
    "}\n",
    "\n",
    "# Resonance index colors for outlines\n",
    "res_index_colors = [  # High contrast with color_map\n",
    "    'red',     # 3\n",
    "    'blue',\n",
    "    'lime',    # 4\n",
    "    'green',   # 5\n",
    "    'yellow',  # 6\n",
    "    'purple',  # 7\n",
    "    'orange',  # 8\n",
    "    'brown',   # 9\n",
    "    'cyan',    # 10\n",
    "    'magenta', # 11\n",
    "    'pink',    # 12\n",
    "        # 13\n",
    "    # etc.\n",
    "]\n",
    "\n",
    "def calc_tree_depth(all_parts, part_idx):\n",
    "    \"\"\"\n",
    "    Calculates how deep a particle is in the 'shower tree':\n",
    "    the number of parent links until there is no parent (-1).\n",
    "    \"\"\"\n",
    "    depth = 0\n",
    "    current_label = all_parts[part_idx].part_label\n",
    "    while current_label != -1:\n",
    "        parent_label = next(\n",
    "            (p.part_parent_label for p in all_parts if p.part_label == current_label),\n",
    "            -1\n",
    "        )\n",
    "        if parent_label == -1:\n",
    "            break\n",
    "        current_label = parent_label\n",
    "        depth += 1\n",
    "    return depth\n",
    "\n",
    "def draw_3d_network(G, pos, node_colors, node_sizes, node_edgecolors, ax):\n",
    "    \"\"\"\n",
    "    A custom routine to plot a NetworkX graph in 3D with node outlines.\n",
    "    \"\"\"\n",
    "    # Draw edges\n",
    "    for (n1, n2) in G.edges():\n",
    "        x1, y1, z1 = pos[n1]\n",
    "        x2, y2, z2 = pos[n2]\n",
    "        ax.plot([x1, x2], [y1, y2], [z1, z2], c='black', alpha=1, linewidth = 1.5)\n",
    "\n",
    "    # Draw nodes (as a single scatter plot)\n",
    "    xs, ys, zs = [], [], []\n",
    "    for node in G.nodes():\n",
    "        x, y, z = pos[node]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "        zs.append(z)\n",
    "\n",
    "    ax.scatter(\n",
    "        xs,\n",
    "        ys,\n",
    "        zs,\n",
    "        c=node_colors,\n",
    "        s=node_sizes,\n",
    "        edgecolors=node_edgecolors,\n",
    "        linewidths=1.5,\n",
    "        alpha=0.5  # Change the alpha of the edgecolor\n",
    "    )\n",
    "\n",
    "def build_shower_graph(particles):\n",
    "    \"\"\"\n",
    "    Builds a NetworkX DiGraph for the given shower particles,\n",
    "    computes node attributes, and returns (G, pos).\n",
    "    pos is a dict {node_label: (x,y,z)} used for 3D drawing.\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    pos = {}\n",
    "\n",
    "    for idx, p in enumerate(particles):\n",
    "        depth = calc_tree_depth(particles, idx)\n",
    "        G.add_node(\n",
    "            p.part_label,\n",
    "            prong_label=p.prong_label,\n",
    "            energy=p.mom.e,\n",
    "            depth=depth,\n",
    "            resonance_origin=p.resonance_origin\n",
    "        )\n",
    "        if p.part_parent_label > -1:\n",
    "            G.add_edge(p.part_parent_label, p.part_label)\n",
    "\n",
    "        # 3D position: (eta, phi, depth)\n",
    "        pos[p.part_label] = (\n",
    "            p.mom.eta.item(),\n",
    "            p.mom.phi.item(),\n",
    "            depth\n",
    "        )\n",
    "\n",
    "    return G, pos\n",
    "\n",
    "def make_shower_3d_plot(shower_particles):\n",
    "    \"\"\"\n",
    "    Given a list of shower particles, build the graph and\n",
    "    plot it in a 3D figure. Returns the figure and axis.\n",
    "    \"\"\"\n",
    "    G_shower, pos_shower = build_shower_graph(shower_particles)\n",
    "\n",
    "    # Node face colors (by prong label)\n",
    "    prong_labels = nx.get_node_attributes(G_shower, 'prong_label')\n",
    "    node_colors = [color_map[prong_labels[node]] for node in G_shower.nodes]\n",
    "\n",
    "    # Node sizes (combine energy + depth if desired)\n",
    "    node_depths = nx.get_node_attributes(G_shower, 'depth')\n",
    "    node_sizes = [\n",
    "        (G_shower.nodes[node]['energy'] * 10)\n",
    "        for node in G_shower.nodes\n",
    "    ]\n",
    "\n",
    "    # Resonance-based outline color\n",
    "    resonance_edgecolors = []\n",
    "    for node in G_shower.nodes:\n",
    "        resonance_label = G_shower.nodes[node].get('resonance_origin', '')\n",
    "        if 'Resonance' in resonance_label:\n",
    "            # e.g. \"Resonance_10.0_1\" => [\"Resonance\", \"10.0\", \"1\"]\n",
    "            parts = resonance_label.split('_')\n",
    "            try:\n",
    "                res_index = int(parts[-1])\n",
    "                edge_col = res_index_colors[res_index % len(res_index_colors)]\n",
    "            except ValueError:\n",
    "                edge_col = 'black'\n",
    "            resonance_edgecolors.append(edge_col)\n",
    "        else:\n",
    "            resonance_edgecolors.append('none')\n",
    "\n",
    "    # Create the figure and 3D axis\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = Axes3D(fig) \n",
    "    ax.set_title(\"Shower 3D View: (eta, phi, depth)\")\n",
    "\n",
    "    # Draw the network in 3D\n",
    "    draw_3d_network(\n",
    "        G_shower,\n",
    "        pos_shower,\n",
    "        node_colors=node_colors,\n",
    "        node_sizes=node_sizes,\n",
    "        node_edgecolors=resonance_edgecolors,\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "\n",
    "    ax.set_xlabel(f'$\\eta$')\n",
    "    ax.set_ylabel(f'$\\phi$')\n",
    "    ax.set_zlabel('Tree Depth')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "%matplotlib widget \n",
    "make_shower_3d_plot(realisticdata_sig_2p_16part[1][0])\n",
    "# make_shower_3d_plot(raw_realisticdata_sig_2p_16part[4][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_shower_data = np.array(f['full_shower'][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget  # enable interactive widget backend\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "# Example prong-label color map\n",
    "color_map = {\n",
    "    -1: 'gray',\n",
    "     0: 'yellow',\n",
    "     1: 'red',\n",
    "     2: 'blue',\n",
    "     3: 'green',\n",
    "     4: 'purple'\n",
    "}\n",
    "\n",
    "# Resonance index colors for outlines\n",
    "res_index_colors = [\n",
    "    'blue',    # 1\n",
    "\n",
    "    'green',   # 3\n",
    "    'orange',  # 4\n",
    "    'purple',  # 5\n",
    "    'brown',   # 6\n",
    "    'cyan',    # 7\n",
    "    # etc.\n",
    "]\n",
    "\n",
    "def calc_tree_depth(all_parts, part_idx):\n",
    "    \"\"\"\n",
    "    Calculates how deep a particle is in the 'shower tree':\n",
    "    the number of parent links until there is no parent (-1).\n",
    "    \"\"\"\n",
    "    depth = 0\n",
    "    current_label = all_parts[part_idx].part_label\n",
    "    while current_label != -1:\n",
    "        parent_label = next(\n",
    "            (p.part_parent_label for p in all_parts if p.part_label == current_label),\n",
    "            -1\n",
    "        )\n",
    "        if parent_label == -1:\n",
    "            break\n",
    "        current_label = parent_label\n",
    "        depth += 1\n",
    "    return depth\n",
    "\n",
    "def draw_3d_network(G, pos, node_colors, node_sizes, node_edgecolors, ax):\n",
    "    \"\"\"\n",
    "    A custom routine to plot a NetworkX graph in 3D with node outlines.\n",
    "    \"\"\"\n",
    "    # Draw edges\n",
    "    for (n1, n2) in G.edges():\n",
    "        x1, y1, z1 = pos[n1]\n",
    "        x2, y2, z2 = pos[n2]\n",
    "        ax.plot([x1, x2], [y1, y2], [z1, z2], c='black', alpha=0.5)\n",
    "\n",
    "    # Draw nodes (as a single scatter plot)\n",
    "    xs, ys, zs = [], [], []\n",
    "    for node in G.nodes():\n",
    "        x, y, z = pos[node]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "        zs.append(z)\n",
    "\n",
    "    ax.scatter(\n",
    "        xs,\n",
    "        ys,\n",
    "        zs,\n",
    "        c=node_colors,\n",
    "        s=node_sizes,\n",
    "        edgecolors=node_edgecolors,\n",
    "        linewidths=2.0\n",
    "    )\n",
    "\n",
    "def build_shower_graph(particles):\n",
    "    \"\"\"\n",
    "    Builds a NetworkX DiGraph for the given shower particles,\n",
    "    computes node attributes, and returns (G, pos).\n",
    "    pos is a dict {node_label: (x,y,z)} used for 3D drawing.\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    pos = {}\n",
    "\n",
    "    for idx, p in enumerate(particles):\n",
    "        depth = calc_tree_depth(particles, idx)\n",
    "        G.add_node(\n",
    "            p.part_label,\n",
    "            prong_label=p.prong_label,\n",
    "            energy=p.mom.e,\n",
    "            depth=depth,\n",
    "        )\n",
    "        if p.part_parent_label > 0:\n",
    "            G.add_edge(p.part_parent_label, p.part_label)\n",
    "\n",
    "        # 3D position: (eta, phi, depth)\n",
    "        pos[p.part_label] = (\n",
    "            p.mom.eta.item(),\n",
    "            p.mom.phi.item(),\n",
    "            depth\n",
    "        )\n",
    "\n",
    "    return G, pos\n",
    "\n",
    "def make_shower_3d_plot(shower_particles):\n",
    "    \"\"\"\n",
    "    Given a list of shower particles, build the graph and\n",
    "    plot it in a 3D figure. Returns the figure and axis.\n",
    "    \"\"\"\n",
    "    G_shower, pos_shower = build_shower_graph(shower_particles)\n",
    "\n",
    "    # Node face colors (by prong label)\n",
    "    prong_labels = nx.get_node_attributes(G_shower, 'prong_label')\n",
    "    node_colors = [color_map[prong_labels[node]] for node in G_shower.nodes]\n",
    "\n",
    "    # Node sizes (combine energy + depth if desired)\n",
    "    node_depths = nx.get_node_attributes(G_shower, 'depth')\n",
    "    node_sizes = [\n",
    "        (G_shower.nodes[node]['energy'] * 10) * (1 + 0.2 * node_depths[node])\n",
    "        for node in G_shower.nodes\n",
    "    ]\n",
    "\n",
    "    \n",
    "\n",
    "    # Create the figure and 3D axis\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = Axes3D(fig) \n",
    "    ax.set_title(\"Shower 3D View: (eta, phi, depth)\")\n",
    "\n",
    "    # Draw the network in 3D\n",
    "    draw_3d_network(\n",
    "        G_shower,\n",
    "        pos_shower,\n",
    "        node_colors=node_colors,\n",
    "        node_sizes=node_sizes,\n",
    "        node_edgecolors = ['black' for _ in G_shower.nodes],\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel('eta')\n",
    "    ax.set_ylabel('phi')\n",
    "    ax.set_zlabel('depth')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "%matplotlib widget \n",
    "# make_shower_3d_plot(realisticdata_sig_2p_16part[1][0])\n",
    "make_shower_3d_plot(raw_realisticdata_sig_2p_16part[4][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "# Extract the particles from the dataset\n",
    "color_map = {-1: 'gray', 0: 'yellow', 1: 'red', 2: 'blue', 3: 'green', 4: 'purple'}\n",
    "\n",
    "\n",
    "for i in range(len(realisticdata_sig_2p_16part[1])):\n",
    "    shower_particles = realisticdata_sig_2p_16part[1][i]\n",
    "    final_state_particles = realisticdata_sig_2p_16part[0][i]\n",
    "\n",
    "    # Create a directed graph for shower particles\n",
    "    G_shower = nx.DiGraph()\n",
    "    for particle in shower_particles:\n",
    "        \n",
    "        G_shower.add_node(particle.part_label, prong_label=particle.prong_label, energy=particle.mom.e)\n",
    "        if particle.part_parent_label > 0:\n",
    "            G_shower.add_edge(particle.part_parent_label, particle.part_label)\n",
    "    \n",
    "    # Get the prong labels for coloring\n",
    "    prong_labels_shower = nx.get_node_attributes(G_shower, 'prong_label')\n",
    "    node_colors_shower = [color_map[prong_labels_shower[node]] for node in G_shower.nodes]\n",
    "    node_sizes_shower = [G_shower.nodes[node]['energy'] * 10 for node in G_shower.nodes]\n",
    "    pos_shower = {particle.part_label: (particle.mom.eta.item(), particle.mom.phi.item()) for particle in shower_particles}\n",
    "\n",
    "    # Create a directed graph for final state particles\n",
    "    G_final = nx.DiGraph()\n",
    "    for particle in final_state_particles:\n",
    "        G_final.add_node(particle.part_label, prong_label=particle.prong_label, energy=particle.mom.e)\n",
    "\n",
    "    # Get the prong labels for coloring\n",
    "    prong_labels_final = nx.get_node_attributes(G_final, 'prong_label')\n",
    "    node_colors_final = [color_map[prong_labels_final[node]] for node in G_final.nodes]\n",
    "    node_sizes_final = [G_final.nodes[node]['energy'] * 10 for node in G_final.nodes]\n",
    "    pos_final = {particle.part_label: (particle.mom.eta.item(), particle.mom.phi.item()) for particle in final_state_particles}\n",
    "\n",
    "    # Draw the graphs side by side\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(24, 8))\n",
    "\n",
    "    # Plot shower particles\n",
    "    axes[0].set_title('Full Shower')\n",
    "    nx.draw(G_shower, pos_shower, with_labels=True, node_color=node_colors_shower, node_size=node_sizes_shower, font_size=10, font_color='black', ax=axes[0])\n",
    "\n",
    "    # Plot final state particles\n",
    "    axes[1].set_title('Final State Particles')\n",
    "    nx.draw(G_final, pos_final, with_labels=False, node_color=node_colors_final, node_size=node_sizes_final, font_size=10, font_color='black', ax=axes[1])\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_part = realistic_sig_2p_16part.draw_first_particle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomdraw_phi = np.random.uniform(0,2*np.pi)\n",
    "\n",
    "z,theta,m1,m2 = realistic_sig_2p_16part.randz(mother = first_part, iPhi = randomdraw_phi)\n",
    "resonance_mass = 30\n",
    "\n",
    "d1 = np.abs(m1-resonance_mass)\n",
    "d2 = np.abs(m2-resonance_mass)\n",
    "if d1 < d2:\n",
    "    print(\"Closest mass: \", m1)\n",
    "    mass_shift = resonance_mass - m1\n",
    "    print('Mass shift: ', mass_shift)\n",
    "    m1 = resonance_mass\n",
    "    m2 = m2 - mass_shift\n",
    "    print('Adjusted m2: ', m2)\n",
    "else:\n",
    "    print(\"Closest mass: \", m2)\n",
    "    mass_shift = resonance_mass - m2\n",
    "    print('Mass shift: ', mass_shift)\n",
    "    m2 = resonance_mass\n",
    "    m1 = m1 - mass_shift\n",
    "    print('Adjusted m1: ', m1)\n",
    "\n",
    "resonance_mom, quark_mom = realistic_sig_2p_16part.dau2(first_part,resonance_mass,theta,z,randomdraw_phi)\n",
    "print(resonance_mom.m, quark_mom.m)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1,d2,z,theta = realistic_sig_2p_16part.hardsplit(first_part,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1.mom.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2.mom.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_vec= [109.736, 88.8394, 3.75664e-15, 50.3493]\n",
    "m = np.sqrt(four_vec[0]**2 - four_vec[1]**2 - four_vec[2]**2 - four_vec[3]**2)\n",
    "p = np.sqrt(four_vec[1]**2 + four_vec[2]**2 + four_vec[3]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theta_func(z,m,m1,m2,p):\n",
    "    val0=(1./(4.*p**2))*(m**4-2*(m**2)*(m1**2+m2**2)+(m1**2-m2**2)**2)\n",
    "    val1=z*(m1**2-m2**2)\n",
    "    val2=m1**2\n",
    "    val3=z*(1-z)*m**2\n",
    "    num=(val0+val1-val2+val3)\n",
    "    den=(p**2+m**2)\n",
    "    return np.arctan(np.sqrt(num/den))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_range = np.linspace(1, 50, 100)\n",
    "z_raneg = np.linspace(0.3, 1, 100)\n",
    "m1 = 30\n",
    "y = theta_func(0.1,m,m1,m2_range,p)\n",
    "Z, M2 = np.meshgrid(z_raneg, m2_range)\n",
    "theta_values = np.vectorize(theta_func)(Z, m, m1, M2, p)\n",
    "\n",
    "plt.contourf(M2, Z, theta_values, levels=50, cmap='viridis')\n",
    "plt.colorbar(label='theta')\n",
    "plt.xlabel(\"m2\")\n",
    "plt.ylabel(\"z\")\n",
    "plt.title(\"2D Color Plot of theta\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('processed_gromov_toy_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get unique values for n_parts and n_prong\n",
    "unique_n_parts = df['n_parts'].unique()\n",
    "unique_n_prongs = df['n_prong'].unique()\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(len(unique_n_parts), len(unique_n_prongs), figsize=(5 * len(unique_n_prongs), 5 * len(unique_n_parts)), sharex=True, sharey=True)\n",
    "\n",
    "# Plot histograms\n",
    "for i, n_parts in enumerate(unique_n_parts):\n",
    "    for j, n_prong in enumerate(unique_n_prongs):\n",
    "        ax = axes[i, j]\n",
    "        subset = df[(df['n_parts'] == n_parts) & (df['n_prong'] == n_prong)]\n",
    "        ax.hist(subset['delta'], bins=50, density=True, alpha=0.6, label=f'n_parts={n_parts}, n_prong={n_prong}')\n",
    "        ax.set_title(f'n_parts={n_parts}, n_prong={n_prong}')\n",
    "        ax.set_xlabel('delta')\n",
    "        ax.set_ylabel('Density')\n",
    "        # ax.legend()\n",
    "\n",
    "        \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('per_particle_gromov_toy_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shower = df[df['data_type'] == 'shower']\n",
    "df_fs = df[df['data_type'] == 'final_state']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df_fs.groupby(['num_parts', 'num_prong'])\n",
    "\n",
    "# Define the bins\n",
    "rel_bins = np.linspace(0, 2, 50)\n",
    "\n",
    "bins = np.linspace(0, 0.1, 50)\n",
    "\n",
    "\n",
    "for combo in product(df_fs['num_parts'].unique(), df_fs['num_prong'].unique()):\n",
    "    plt.figure()\n",
    "    for k in df_fs['k'].unique():\n",
    "        try:\n",
    "            subset = grouped.get_group(combo)\n",
    "            k_grouped = subset.groupby(['k']).get_group(k)\n",
    "            plt.hist(k_grouped['rel_delta'], bins=rel_bins, label=f'K = {k}', histtype='step',density = 'True')\n",
    "            plt.title(f'n_parts={combo[0]}, n_prong={combo[1]}')\n",
    "            plt.legend()\n",
    "            plt.xlabel('rel_delta')\n",
    "            plt.ylabel('Density')\n",
    "        except KeyError:\n",
    "            # This combination doesn't exist in the data\n",
    "            pass\n",
    "    plt.show()\n",
    "    plt.figure()\n",
    "    for k in df_fs['k'].unique():\n",
    "        try:\n",
    "            subset = grouped.get_group(combo)\n",
    "            k_grouped = subset.groupby(['k']).get_group(k)\n",
    "            plt.hist(k_grouped['delta'], bins=bins, label=f'K = {k}', histtype='step',density = 'True')\n",
    "            plt.title(f'n_parts={combo[0]}, n_prong={combo[1]}')\n",
    "            plt.legend()\n",
    "            plt.xlabel('delta')\n",
    "            plt.xscale('log')\n",
    "            plt.ylabel('Density')\n",
    "        except KeyError:\n",
    "            # This combination doesn't exist in the data\n",
    "            pass\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realisticdata_sig_2p_16part[4][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "# Extract the particles from the dataset\n",
    "color_map = {-1: 'gray', 0: 'yellow', 1: 'red', 2: 'blue', 3: 'green', 4: 'purple'}\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    shower_particles = realisticdata_sig_2p_16part[4][i]\n",
    "    final_state_particles = realisticdata_sig_2p_16part[3][i]\n",
    "\n",
    "    # Create a directed graph for shower particles\n",
    "    G_shower = nx.DiGraph()\n",
    "    for particle in shower_particles:\n",
    "        G_shower.add_node(particle.part_label, prong_label=particle.prong_label, energy=particle.mom.e)\n",
    "        if particle.part_parent_label > 0:\n",
    "            G_shower.add_edge(particle.part_parent_label, particle.part_label)\n",
    "\n",
    "    # Get the prong labels for coloring\n",
    "    prong_labels_shower = nx.get_node_attributes(G_shower, 'prong_label')\n",
    "    node_colors_shower = [color_map[prong_labels_shower[node]] for node in G_shower.nodes]\n",
    "    node_sizes_shower = [G_shower.nodes[node]['energy'] * 10 for node in G_shower.nodes]\n",
    "    pos_shower = {particle.part_label: (particle.mom.eta.item(), particle.mom.phi.item()) for particle in shower_particles}\n",
    "\n",
    "    # Create a directed graph for final state particles\n",
    "    G_final = nx.DiGraph()\n",
    "    for particle in final_state_particles:\n",
    "        G_final.add_node(particle.part_label, prong_label=particle.prong_label, energy=particle.mom.e)\n",
    "\n",
    "    # Get the prong labels for coloring\n",
    "    prong_labels_final = nx.get_node_attributes(G_final, 'prong_label')\n",
    "    node_colors_final = [color_map[prong_labels_final[node]] for node in G_final.nodes]\n",
    "    node_sizes_final = [G_final.nodes[node]['energy'] * 10 for node in G_final.nodes]\n",
    "    pos_final = {particle.part_label: (particle.mom.eta.item(), particle.mom.phi.item()) for particle in final_state_particles}\n",
    "\n",
    "    # Draw the graphs side by side\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(24, 8))\n",
    "\n",
    "    # Plot shower particles\n",
    "    axes[0].set_title('Full Shower')\n",
    "    nx.draw(G_shower, pos_shower, with_labels=False, node_color=node_colors_shower, node_size=node_sizes_shower, font_size=10, font_color='black', ax=axes[0])\n",
    "\n",
    "    # Plot final state particles\n",
    "    axes[1].set_title('Final State Particles')\n",
    "    nx.draw(G_final, pos_final, with_labels=False, node_color=node_colors_final, node_size=node_sizes_final, font_size=10, font_color='black', ax=axes[1])\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_hyp(dismat):\n",
    "    p = 0\n",
    "    row = dismat[p, :][None, :]\n",
    "    col = dismat[:, p][:, None]\n",
    "    XY_p = 0.5 * (row + col - dismat)\n",
    "    maxmin = torch.minimum(XY_p[:, :, None], XY_p[None, :, :]).max(1).values\n",
    "    return (maxmin - XY_p).max()\n",
    "\n",
    "def find_neighbors_knn(four_momentum_tensor, dists, index, k=5):\n",
    "    # Randomly select a point\n",
    "    num_points = four_momentum_tensor.shape[0]\n",
    "    selected_point = four_momentum_tensor[index]\n",
    "    \n",
    "    # Find the indices of the k-nearest neighbors\n",
    "    neighbors_indices = torch.topk(dists[index], k, largest=False).indices\n",
    "\n",
    "    neighbors = four_momentum_tensor[neighbors_indices]\n",
    "\n",
    "    return selected_point, neighbors, neighbors_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_state_particles\n",
    "all_k = [5,8,12]\n",
    "e_eta_phi = []\n",
    "results = []\n",
    "for part in final_state_particles:\n",
    "    mom = part.mom\n",
    "    e_eta_phi.append([mom.e, mom.eta.item(), mom.phi.item()])\n",
    "\n",
    "e_eta_phi = np.array(e_eta_phi)\n",
    "four_momentum_tensor = torch.tensor(e_eta_phi)\n",
    "\n",
    "# Extract energy, eta, phi\n",
    "energies = four_momentum_tensor[:, 0]\n",
    "normalized_energies = energies / energies.sum()\n",
    "energies = normalized_energies\n",
    "etas = four_momentum_tensor[:, 1]\n",
    "phis = four_momentum_tensor[:, 2]\n",
    "\n",
    "# Compute pairwise energy differences\n",
    "energy_diffs = torch.abs(energies[:, None] - energies[None, :])\n",
    "delta_eta = etas[:, None] - etas[None, :]\n",
    "delta_phi = phis[:, None] - phis[None, :]\n",
    "delta_phi = torch.remainder(delta_phi + np.pi, 2 * np.pi) - np.pi\n",
    "delta_R = torch.sqrt(delta_eta ** 2 + delta_phi ** 2)\n",
    "\n",
    "R = 1\n",
    "dists = (energy_diffs * delta_R) / R\n",
    "delta = delta_hyp(dists)\n",
    "for j in range(len(four_momentum_tensor)):\n",
    "    n_parts = len(four_momentum_tensor)\n",
    "\n",
    "    for k in all_k:\n",
    "        # print(k)\n",
    "        selected_point, neighbors, neighbors_indices = find_neighbors_knn(four_momentum_tensor, dists, index=j, k=k)\n",
    "\n",
    "        # Extract the submatrix for the neighbors\n",
    "        neighbors_dists = dists[neighbors_indices][:, neighbors_indices]\n",
    "\n",
    "        delta = delta_hyp(neighbors_dists)\n",
    "        diam = neighbors_dists.max()\n",
    "        rel_delta = (2 * delta) / diam\n",
    "\n",
    "        # Calculate c based on relative delta mean\n",
    "        c = (0.144 / rel_delta) ** 2\n",
    "\n",
    "        # Save the results\n",
    "        results.append({\n",
    "            'selected_point_energy': selected_point[0].item(),\n",
    "            'selected_point_eta': selected_point[1].item(),\n",
    "            'selected_point_phi': selected_point[2].item(),\n",
    "            'num_parts': n_parts,\n",
    "            'k': k,\n",
    "            'delta': delta.item(),\n",
    "            'rel_delta': rel_delta.item(),\n",
    "            'c': c.item(),\n",
    "        })\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['k'] == 5].plot.scatter(x='selected_point_energy', y='delta')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_event(pfcands, name):\n",
    "\n",
    "    pt = pfcands[:,0]\n",
    "    eta = pfcands[:,1]\n",
    "    phi = pfcands[:,2]\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.scatter(eta,phi,s=pt*10, alpha=0.2)\n",
    "    ax.set_xlabel('eta')\n",
    "    ax.set_ylabel('phi')\n",
    "    ax.set_xlim([-1,1])\n",
    "    ax.set_ylim([-1,1])\n",
    "    fig.savefig(f'figures/{name}.png')\n",
    "\n",
    "    \n",
    "def plot_two_event(pfcand1, pfcand2,augmentation_name):\n",
    "    # Extract pt, eta, and phi from both events\n",
    "    pt1 = pfcand1[:,0]\n",
    "    eta1 = pfcand1[:,1]\n",
    "    phi1 = pfcand1[:,2]\n",
    "\n",
    "    pt2 = pfcand2[:,0]\n",
    "    eta2 = pfcand2[:,1]\n",
    "    phi2 = pfcand2[:,2]\n",
    "\n",
    "    # Create subplots with two axes side by side\n",
    "    fig, axes = plt.subplots(2,1, figsize=(6, 10))\n",
    "\n",
    "    # Plot the first event\n",
    "    axes[0].scatter(eta1, phi1, s=pt1*10, alpha=0.2)\n",
    "    axes[0].set_xlabel('eta')\n",
    "    axes[0].set_ylabel('phi')\n",
    "    axes[0].set_xlim([-1, 1])\n",
    "    axes[0].set_ylim([-1, 1])\n",
    "    axes[0].set_title(f'Original Jet')\n",
    "\n",
    "    # Plot the second event\n",
    "    axes[1].scatter(eta2, phi2, s=pt2*10, alpha=0.2)\n",
    "    axes[1].set_xlabel('eta')\n",
    "    axes[1].set_ylabel('phi')\n",
    "    axes[1].set_xlim([-1, 1])\n",
    "    axes[1].set_ylim([-1, 1])\n",
    "    axes[1].set_title(f'{augmentation_name}')\n",
    "\n",
    "    # Adjust layout and display\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "#     fig.savefig(f'figures/{name}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pylorentz import Momentum4\n",
    " \n",
    "def soft_splitting_augmentation(gen_function, particles_list,n_splits_mid, n_splits_std):\n",
    "    particles = copy.deepcopy(particles_list)\n",
    "    n_splittings = int(np.random.normal(loc=n_splits_mid, scale=n_splits_std))\n",
    "#     print(f'Splitting {n_splittings} particles with soft splitting')\n",
    "    for _ in range(n_splittings):\n",
    "        dau1, dau2, z, theta = gen_function.softsplit(particles[0])\n",
    "        particles.pop(0)\n",
    "        gen_function.reverse_insort(particles, dau1)\n",
    "        gen_function.reverse_insort(particles, dau2)\n",
    "        \n",
    "    return particles\n",
    "\n",
    "# new function\n",
    "# randomly selects root\n",
    "# merges it with lowest particle energy weighted distance \n",
    "def soft_merging_augmentation(gen_function, particles_list,n_merges_mid, n_merges_std):\n",
    "    particles = copy.deepcopy(particles_list)\n",
    "    all_e = []\n",
    "    all_phi = []\n",
    "    all_eta = []\n",
    "    for p in particles:\n",
    "        mom = p.mom\n",
    "        all_e.append(mom[0])\n",
    "        all_phi.append(mom.phi)\n",
    "        all_eta.append(mom.eta)\n",
    "        \n",
    "    all_e = np.array(all_e)\n",
    "    all_phi = np.array(all_phi)\n",
    "    all_eta = np.array(all_eta)\n",
    "\n",
    "    phi_diff = (all_phi[:, np.newaxis] - all_phi[np.newaxis, :]).squeeze()\n",
    "    eta_diff = (all_eta[:, np.newaxis] - all_eta[np.newaxis, :]).squeeze()\n",
    "\n",
    "    pairwise_matrix = ((phi_diff**2 + eta_diff**2) * (all_e[:, np.newaxis] + all_e[np.newaxis, :]) / 2) + 1000*np.eye(len(particles))\n",
    "    print(pairwise_matrix.shape)\n",
    "    n_merges = int(np.random.normal(loc=n_merges_mid, scale=n_merges_std))\n",
    "    for _ in range(n_merges):\n",
    "        root = int(np.abs(np.random.normal(loc=0, scale=2)))\n",
    "        dau2_id = np.argmin(pairwise_matrix[-root])\n",
    "        \n",
    "        mother = gen_function.softcombine(particles[-root],particles[dau2_id])\n",
    "        if root > dau2_id:\n",
    "            particles.pop(root)\n",
    "            particles.pop(dau2_id)\n",
    "        else:\n",
    "            particles.pop(dau2_id)\n",
    "            particles.pop(root)\n",
    "        # need to update pairwise matrix to remove particles dropped and add info for new particles \n",
    "#         gen_function.reverse_insort(particles, mother)\n",
    "        mother_index = gen_function.reverse_insort(particles, mother)\n",
    "        # Update the pairwise matrix:\n",
    "        # 1. Remove the rows/columns of the merged particles\n",
    "        all_e = []\n",
    "        all_phi = []\n",
    "        all_eta = []\n",
    "        for p in particles:\n",
    "            mom = p.mom\n",
    "            all_e.append(mom[0])\n",
    "            all_phi.append(mom.phi)\n",
    "            all_eta.append(mom.eta)\n",
    "\n",
    "        all_e = np.array(all_e)\n",
    "        all_phi = np.array(all_phi)\n",
    "        all_eta = np.array(all_eta)\n",
    "\n",
    "        phi_diff = (all_phi[:, np.newaxis] - all_phi[np.newaxis, :]).squeeze()\n",
    "        eta_diff = (all_eta[:, np.newaxis] - all_eta[np.newaxis, :]).squeeze()\n",
    "\n",
    "        pairwise_matrix = ((phi_diff**2 + eta_diff**2) * (all_e[:, np.newaxis] + all_e[np.newaxis, :]) / 2) + 1000*np.eye(len(particles))\n",
    "\n",
    "        \n",
    "    return particles\n",
    "\n",
    "\n",
    "def rotation_augmentation(gen_function, particles_list):\n",
    "    particles = copy.deepcopy(particles_list)\n",
    "    n_particles = len(particles_list)\n",
    "    theta = np.random.uniform(low=0,high = np.pi)\n",
    "#     print(f'Rotating {n_particles} particles')\n",
    "    for i in range(n_particles):\n",
    "        rotated_particle_mom = gen_function.rotatePhi(particles[i].mom,theta)\n",
    "        particles[i].mom = rotated_particle_mom\n",
    "        \n",
    "    return particles\n",
    "\n",
    "def rotation_matrix_x(theta):\n",
    "    # Create an identity matrix\n",
    "    rotation_matrix = np.eye(4)\n",
    "    \n",
    "    # Set the rotation part for the y-z plane\n",
    "    rotation_matrix[1, 1] = np.cos(theta)\n",
    "    rotation_matrix[1, 2] = -np.sin(theta)\n",
    "    rotation_matrix[2, 1] = np.sin(theta)\n",
    "    rotation_matrix[2, 2] = np.cos(theta)\n",
    "    \n",
    "    return rotation_matrix\n",
    "\n",
    "\n",
    "\n",
    "def Lorentz_xy_rotation_augmentation(gen_function, particles_list):\n",
    "    particles = copy.deepcopy(particles_list)\n",
    "    n_particles = len(particles_list)\n",
    "    theta = np.random.uniform(low=0,high = 0.5)\n",
    "    M = rotation_matrix_x(theta)\n",
    "    print(f'Rotating {n_particles} particles')\n",
    "    for i in range(n_particles):\n",
    "        mom = particles[i].mom\n",
    "        mom_vec = np.array([mom.p_t,mom.p_x,mom.p_y,mom.p_z])\n",
    "        rotated_mom = M@mom_vec\n",
    "        new_mom = Momentum4(rotated_mom[0],rotated_mom[1],rotated_mom[2],rotated_mom[3])\n",
    "        particles[i].mom = new_mom\n",
    "        \n",
    "    return particles\n",
    "\n",
    "def boost_matrix_z(eta):\n",
    "    # Create an identity matrix\n",
    "    rotation_matrix = np.eye(4)\n",
    "    \n",
    "    # Set the rotation part for the y-z plane\n",
    "    rotation_matrix[0, 0] = np.cosh(eta)\n",
    "    rotation_matrix[1, 3] = np.sinh(eta)\n",
    "    rotation_matrix[0, 3] = np.sinh(eta)\n",
    "    rotation_matrix[3, 3] = np.cosh(eta)\n",
    "    \n",
    "    return rotation_matrix\n",
    "    \n",
    "def Lorentz_z_boost_augmentation(gen_function, particles_list):\n",
    "    particles = copy.deepcopy(particles_list)\n",
    "    n_particles = len(particles_list)\n",
    "    eta = np.random.normal(loc=0, scale=0.25)\n",
    "    M = boost_matrix_z(eta)\n",
    "    print(f'Rotating {n_particles} particles')\n",
    "    for i in range(n_particles):\n",
    "        mom = particles[i].mom\n",
    "        mom_vec = np.array([mom.p_t,mom.p_x,mom.p_y,mom.p_z])\n",
    "        boosted_mom = M@mom_vec\n",
    "        new_mom = Momentum4(boosted_mom[0],boosted_mom[1],boosted_mom[2],boosted_mom[3])\n",
    "        particles[i].mom = new_mom\n",
    "        \n",
    "    return particles  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a random test dataframe with some categorical 'Prongs' and numerical values\n",
    "np.random.seed(42)  # For reproducibility\n",
    "n_samples = 100\n",
    "df = pd.DataFrame({\n",
    "    'PCA1': np.random.randn(n_samples),\n",
    "    'PCA2': np.random.randn(n_samples),\n",
    "    'PCA3': np.random.randn(n_samples),\n",
    "    'Prongs': np.random.choice(['1 Prong', '2 Prong', '3 Prong', '4 Prong'], n_samples)\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(ax._legend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pairplot and keep the default legend\n",
    "ax = sns.pairplot(df, hue='Prongs', kind=\"scatter\", palette='tab10', diag_kind='kde')\n",
    "ax._legend.remove()\n",
    "\n",
    "# Move the legend using the underlying Matplotlib API\n",
    "ax.add_legend(title=\"Prongs\", bbox_to_anchor=(0.5, -0.05), loc='center', ncol=4, frameon=False)\n",
    "# Adjust the font size for the legend\n",
    "ax.map_lower(sns.kdeplot, levels=4, color=\".2\")\n",
    "plt.setp(ax._legend.get_texts(), fontsize='30')\n",
    "plt.setp(ax._legend.get_title(), fontsize='30')\n",
    "\n",
    "# Adjust layout to avoid overlap\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "with h5py.File('test_data/jet_2_0.h5', 'r') as f:\n",
    "    # List all datasets in the file\n",
    "    print(\"Datasets in the file:\", list(f.keys()))\n",
    "    \n",
    "    # Load the datasets\n",
    "    data = f['data'][:]\n",
    "    aug_data = f['aug_data'][:]\n",
    "\n",
    "index = np.random.randint(0,1000)    \n",
    "plot_two_event(data[index].reshape(-1,3),aug_data[index].reshape(-1,3),'Augmentated Jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "original_jet = realisticdata_sig_2p_16part[0][0].reshape(-1,3)\n",
    "\n",
    "augmented_jet = Lorentz_z_boost_augmentation(realistic_sig_2p_16part,list(realisticdata_sig_2p_16part[3][0]))\n",
    "augmented_arr = []\n",
    "for j in range(len(augmented_jet)):\n",
    "    augmented_arr.append(augmented_jet[j].mom.p_t)\n",
    "    augmented_arr.append(augmented_jet[j].mom.eta)\n",
    "    augmented_arr.append(augmented_jet[j].mom.phi)\n",
    "augmented_arr = np.array(augmented_arr)\n",
    "\n",
    "plot_two_event(original_jet,augmented_arr.reshape(-1,3),'Z-boost Augmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "original_jet = realisticdata_sig_2p_16part[0][0].reshape(-1,3)\n",
    "\n",
    "augmented_jet = Lorentz_xy_rotation_augmentation(realistic_sig_2p_16part,list(realisticdata_sig_2p_16part[3][0]))\n",
    "augmented_arr = []\n",
    "for j in range(len(augmented_jet)):\n",
    "    augmented_arr.append(augmented_jet[j].mom.p_t)\n",
    "    augmented_arr.append(augmented_jet[j].mom.eta)\n",
    "    augmented_arr.append(augmented_jet[j].mom.phi)\n",
    "augmented_arr = np.array(augmented_arr)\n",
    "\n",
    "plot_two_event(original_jet,augmented_arr.reshape(-1,3),'X-Y Rotation Augmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "original_jet = realisticdata_sig_2p_16part[0][0].reshape(-1,3)\n",
    "\n",
    "augmented_jet = Lorentz_z_boost_augmentation(realistic_sig_2p_16part,list(realisticdata_sig_2p_16part[3][0]))\n",
    "augmented_arr = []\n",
    "for j in range(len(augmented_jet)):\n",
    "    augmented_arr.append(augmented_jet[j].mom.p_t)\n",
    "    augmented_arr.append(augmented_jet[j].mom.eta)\n",
    "    augmented_arr.append(augmented_jet[j].mom.phi)\n",
    "augmented_arr = np.array(augmented_arr)\n",
    "\n",
    "plot_two_event(original_jet,augmented_arr.reshape(-1,3),'Z-boost Augmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "original_jet = realisticdata_sig_2p_16part[0][0].reshape(-1,3)\n",
    "\n",
    "augmented_jet = soft_merging_augmentation(realistic_sig_2p_16part,list(realisticdata_sig_2p_16part[3][0]),5,2)\n",
    "augmented_arr = []\n",
    "for j in range(len(augmented_jet)):\n",
    "    augmented_arr.append(augmented_jet[j].mom.p_t)\n",
    "    augmented_arr.append(augmented_jet[j].mom.eta)\n",
    "    augmented_arr.append(augmented_jet[j].mom.phi)\n",
    "augmented_arr = np.array(augmented_arr)\n",
    "\n",
    "plot_two_event(original_jet,augmented_arr.reshape(-1,3),'Soft Merging Augmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_augmentation(gen_function,data,aug_fn):\n",
    "    \n",
    "    augmented_jet = aug_fn(gen_function,list(data),5,2)\n",
    "    augmented_arr = []\n",
    "    for j in range(len(augmented_jet)):\n",
    "        augmented_arr.append(augmented_jet[j].mom.p_t)\n",
    "        augmented_arr.append(augmented_jet[j].mom.eta)\n",
    "        augmented_arr.append(augmented_jet[j].mom.phi)\n",
    "    augmented_arr = np.array(augmented_arr)\n",
    "    return augmented_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def gen_data_pairs(out_dir, n_prongs, n_samples,n_parts, functions):\n",
    "    gen_function = realistic_generator(\"signal\",n_prongs, n_parts, True)\n",
    "    data_arr,_,_,data_particles = gen_function.generate_dataset(n_samples)\n",
    "    aug_arr = []\n",
    "    for d in data_particles:\n",
    "        cur_fun = random.choice(functions)\n",
    "        cur_aug_arr = apply_augmentation(gen_function, d,cur_fun)\n",
    "        aug_arr.append(cur_aug_arr)\n",
    "    return data_arr, aug_arr\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, aug_data = gen_data_pairs('',\n",
    "               1,\n",
    "               10,\n",
    "               24,\n",
    "#                [soft_splitting_augmentation,soft_merging_augmentation]\n",
    "               [soft_merging_augmentation]\n",
    "               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_two_event(data[0].reshape(-1,3),aug_data[0].reshape(-1,3),'Augmentation Pair')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_parts = np. \n",
    "realisticdata_sig_2p_16part[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_jet = realisticdata_sig_2p_16part[0][0].reshape(-1,3)\n",
    "\n",
    "augmented_jet = Lorentz_xy_rotation_augmentation(realistic_sig_2p_16part,list(realisticdata_sig_2p_16part[3][0]))\n",
    "augmented_arr = []\n",
    "for j in range(len(augmented_jet)):\n",
    "    augmented_arr.append(augmented_jet[j].mom.p_t)\n",
    "    augmented_arr.append(augmented_jet[j].mom.eta)\n",
    "    augmented_arr.append(augmented_jet[j].mom.phi)\n",
    "augmented_arr = np.array(augmented_arr)\n",
    "\n",
    "plot_two_event(original_jet,augmented_arr.reshape(-1,3),'Rotation Augmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_jet = realisticdata_sig_2p_16part[0][0].reshape(-1,3)\n",
    "\n",
    "augmented_jet = soft_splitting_augmentation(realistic_sig_2p_16part,list(realisticdata_sig_2p_16part[3][0]),10,2)\n",
    "augmented_arr = []\n",
    "for j in range(len(augmented_jet)):\n",
    "    augmented_arr.append(augmented_jet[j].mom.p_t)\n",
    "    augmented_arr.append(augmented_jet[j].mom.eta)\n",
    "    augmented_arr.append(augmented_jet[j].mom.phi)\n",
    "augmented_arr = np.array(augmented_arr)\n",
    "\n",
    "plot_two_event(original_jet,augmented_arr.reshape(-1,3),'Soft Splitting Augmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_jet = realisticdata_sig_2p_16part[0][0].reshape(-1,3)\n",
    "\n",
    "augmented_jet1 = soft_splitting_augmentation(realistic_sig_2p_16part,list(realisticdata_sig_2p_16part[3][0]),10,2)\n",
    "augmented_jet = rotation_augmentation(realistic_sig_2p_16part,augmented_jet1)\n",
    "augmented_arr = []\n",
    "for j in range(len(augmented_jet)):\n",
    "    augmented_arr.append(augmented_jet[j].mom.p_t)\n",
    "    augmented_arr.append(augmented_jet[j].mom.eta)\n",
    "    augmented_arr.append(augmented_jet[j].mom.phi)\n",
    "augmented_arr = np.array(augmented_arr)\n",
    "\n",
    "plot_two_event(original_jet,augmented_arr.reshape(-1,3),'Soft Splitting + Rotation \\n Augmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_jet = realisticdata_sig_2p_16part[0][0].reshape(-1,3)\n",
    "\n",
    "augmented_jet1 = soft_merging_augmentation(realistic_sig_2p_16part,list(realisticdata_sig_2p_16part[3][0]),10,2)\n",
    "augmented_jet = rotation_augmentation(realistic_sig_2p_16part,augmented_jet1)\n",
    "augmented_arr = []\n",
    "for j in range(len(augmented_jet)):\n",
    "    augmented_arr.append(augmented_jet[j].mom.p_t)\n",
    "    augmented_arr.append(augmented_jet[j].mom.eta)\n",
    "    augmented_arr.append(augmented_jet[j].mom.phi)\n",
    "augmented_arr = np.array(augmented_arr)\n",
    "\n",
    "plot_two_event(original_jet,augmented_arr.reshape(-1,3),'Soft Merging + Rotation \\n Augmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_event(original_jet,arr.reshape(-1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.hist(realisticdata_sig_2p_16part[1][:,0],alpha=0.4,bins=np.linspace(0,0.5,51),density=True,label=\"Hard Splitting\")\n",
    "ax.hist(realisticdata_sig_2p_16part[1][:,1],alpha=0.4,bins=np.linspace(0,0.5,51),density=True,label=\"Soft Splitting\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(r'$z_{g}$')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_yscale('log')\n",
    "#fig.savefig('./figures/paper/realistic_toyjet_momentum_sharing_Log.png')\n",
    "#fig.savefig('./figures/paper/realistic_toyjet_momentum_sharing_Log.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.hist(realistic_sig_2p_16part.zhard,alpha=0.4,bins=np.linspace(0,0.5,51),density=True,label=\"Hard Splitting\")\n",
    "ax.hist(realistic_sig_2p_16part.zsoft,alpha=0.4,bins=np.linspace(0,0.5,51),density=True,label=\"Soft Splitting\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(r'$z_{g}$')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_yscale('log')\n",
    "fig.savefig('./figures/paper/realistic_toyjet_momentum_sharing_Log.png')\n",
    "fig.savefig('./figures/paper/realistic_toyjet_momentum_sharing_Log.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.hist(realistic_sig_2p_16part.zhard,alpha=0.4,bins=np.linspace(0,0.5,51),density=True,label=\"Hard Splitting\")\n",
    "ax.hist(realistic_sig_2p_16part.zsoft,alpha=0.4,bins=np.linspace(0,0.5,51),density=True,label=\"Soft Splitting\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(r'$z_{g}$')\n",
    "ax.set_ylabel('Density')\n",
    "fig.savefig('./figures/paper/realistic_toyjet_momentum_sharing.png')\n",
    "fig.savefig('./figures/paper/realistic_toyjet_momentum_sharing.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as font_manager\n",
    "\n",
    "mpl.rcParams['font.family']='serif'\n",
    "cmfont = font_manager.FontProperties(fname=mpl.get_data_path() + '/fonts/ttf/cmr10.ttf')\n",
    "mpl.rcParams['font.serif']=cmfont.get_name()\n",
    "mpl.rcParams['mathtext.fontset']='cm'\n",
    "mpl.rcParams['axes.unicode_minus']=False\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.hist(simple_sig_2p_16part.zhard,alpha=0.4,bins=np.linspace(0,0.5,51),density=True,label=\"Hard Splitting\")\n",
    "ax.hist(simple_sig_2p_16part.zsoft,alpha=0.4,bins=np.linspace(0,0.5,51),density=True,label=\"Soft Splitting\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(r'$z_{g, simple}$')\n",
    "ax.set_ylabel('Density')\n",
    "ax.text(0.05, 0.73, 'Simple Toy Jet', transform=ax.transAxes)\n",
    "\n",
    "fig.savefig('./figures/paper_JHEP/SimpleToyJet_Zg.png')\n",
    "fig.savefig('./figures/paper_JHEP/SimpleToyJet_Zg.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.hist(simple_sig_2p_16part.thetahard,alpha=0.4,bins=np.arange(0,1.8,0.02),density=True,label=\"Hard Splitting\")\n",
    "ax.hist(simple_sig_2p_16part.thetasoft,alpha=0.4,bins=np.arange(0,1.8,0.02),density=True,label=\"Soft Splitting\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(r'$\\theta_{branch, simple}$')\n",
    "ax.set_ylabel('Density')\n",
    "ax.text(0.55, 0.73, 'Simple Toy Jet', transform=ax.transAxes)\n",
    "\n",
    "fig.savefig('./figures/paper_JHEP/SimpleToyJet_Theta.png')\n",
    "fig.savefig('./figures/paper_JHEP/SimpleToyJet_Theta.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.hist(simple_sig_2p_16part.zhard,alpha=0.4,bins=np.linspace(0,0.5,51),density=True,label=\"Hard Splitting\")\n",
    "ax.hist(simple_sig_2p_16part.zsoft,alpha=0.4,bins=np.linspace(0,0.5,51),density=True,label=\"Soft Splitting\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(r'$z_{g}$')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "fig.savefig('./figures/paper/simple_toyjet_momentum_sharing_Log.png')\n",
    "fig.savefig('./figures/paper/simple_toyjet_momentum_sharing_Log.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.hist(simple_sig_2p_16part.zhard,alpha=0.4,bins=np.linspace(0,0.5,51),density=True,label=\"Hard Splitting\")\n",
    "ax.hist(simple_sig_2p_16part.zsoft,alpha=0.4,bins=np.linspace(0,0.5,51),density=True,label=\"Soft Splitting\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(r'$z_{g}$')\n",
    "ax.set_ylabel('Density')\n",
    "#fig.savefig('./figures/paper/simple_toyjet_momentum_sharing.png')\n",
    "#fig.savefig('./figures/paper/simple_toyjet_momentum_sharing.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sig_2p_8part.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_event(pfcands, name):\n",
    "\n",
    "    pt = pfcands[:,0]\n",
    "    eta = pfcands[:,1]\n",
    "    phi = pfcands[:,2]\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.scatter(eta,phi,s=pt*10, alpha=0.2)\n",
    "    ax.set_xlabel('eta')\n",
    "    ax.set_ylabel('phi')\n",
    "    ax.set_xlim([-1,1])\n",
    "    ax.set_ylim([-1,1])\n",
    "    fig.savefig(f'figures/{name}.png')\n",
    "plot_event(data_sig_3p_8part[99].reshape(-1,3), \"top_3p_8part\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_3p_8part = jet_data_generator(\"signal\",0.00005, 3, 8, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sig_3p_8part = sig_3p_8part.generate_dataset(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_event(data_sig_3p_8part[99].reshape(-1,3), \"top_3p_8part\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "data_sig_2p_2part = sig_2p_2part.generate_dataset(100)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_event(data_sig_2p_2part[5].reshape(-1,3), \"sig_2p_2part\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_2p_3part = jet_data_generator(\"signal\",0.00005, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sig_2p_3part = sig_2p_3part.generate_dataset(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_event(data_sig_2p_3part[5].reshape(-1,3), \"sig_2p_3part\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_3p_3part = jet_data_generator(\"signal\",0.00005, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sig_3p_3part = sig_3p_3part.generate_dataset(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_event(data_sig_3p_3part[1].reshape(-1,3), \"sig_3p_3part\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "top_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
